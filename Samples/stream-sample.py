import torch

torch.classes.__path__ = []

import streamlit as st
import cv2
import os
import tempfile
from ultralytics import YOLO

model = YOLO("./yolov8n.pt")
st.title("YOLOv8 ì‹¤ì‹œê°„ ê°ì²´ íƒì§€")

# ëª¨ë“œ ì„ íƒ (ì›¹ìº  ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ)
mode = st.radio("ì…ë ¥ ëª¨ë“œ ì„ íƒ", ["ì‹¤ì‹œê°„ ì›¹ìº ", "ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"])

if mode == "ì‹¤ì‹œê°„ ì›¹ìº ":
    # ì›¹ìº  ì„¤ì •
    camera_index = st.selectbox("ì¹´ë©”ë¼ ì„ íƒ", [0, 1])
    
    # ì›¹ìº  ì‹œì‘ ë²„íŠ¼
    if st.button("ì›¹ìº  ì‹œì‘"):
        cap = cv2.VideoCapture(camera_index)
        
        if not cap.isOpened():
            st.error("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        else:
            stframe = st.empty()
            stop_button = st.button("ì›¹ìº  ì¤‘ì§€")
            
            # ì›¹ìº  ì •ë³´
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            if fps == 0:
                fps = 30
            
            st.info(f"ì¹´ë©”ë¼ í•´ìƒë„: {frame_width}x{frame_height}, FPS: {fps}")
            
            # ì‹¤ì‹œê°„ ì²˜ë¦¬
            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    st.error("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                results = model(frame)
                
                # íƒì§€ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                detection_text = ""
                
                # ê° íƒì§€ ê²°ê³¼ ì²˜ë¦¬
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì„¸ê¸°
                        class_counts = {}
                        for box in boxes:
                            class_id = int(box.cls[0])
                            class_name = model.names[class_id]
                            confidence = float(box.conf[0])
                            
                            # ì‹ ë¢°ë„ê°€ ì¼ì • ì´ìƒì¸ ê²ƒë§Œ
                            if confidence > 0.5:  # ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥
                                if class_name in class_counts:
                                    class_counts[class_name] += 1
                                else:
                                    class_counts[class_name] = 1
                        
                        # ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        if class_counts:
                            detection_parts = []
                            for class_name, count in class_counts.items():
                                detection_parts.append(f"{count} {class_name}")
                            detection_text = f"0: {frame.shape[1]}x{frame.shape[0]} " + ", ".join(detection_parts)
                
                # ê²°ê³¼ ì¶œë ¥
                if detection_text:
                    st.write(f"íƒì§€ ê²°ê³¼: {detection_text}")
                
                if detection_text.find("cat") > 0:
                    st.success("ğŸ± ê³ ì–‘ì´ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
                
                result_frame = results[0].plot()
                stframe.image(result_frame, channels="BGR")
                
                # í”„ë ˆì„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                import time
                time.sleep(0.1)
            
            cap.release()
            st.success("ì›¹ìº ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

else:
    # ê¸°ì¡´ íŒŒì¼ ì—…ë¡œë“œ ì½”ë“œ
    video_file = st.file_uploader("ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ", type=["mp4", "mov", "avi"])

    if video_file:
        # ì›ë³¸ íŒŒì¼ ì´ë¦„ í™•ë³´ (í™•ì¥ì í¬í•¨)
        filename = video_file.name
        base, ext = os.path.splitext(filename)
        save_dir = "videos"
        os.makedirs(save_dir, exist_ok=True)
        output_path = os.path.join(save_dir, f"{base}_yolo.mp4")

        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_file.read())

        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()

        # ë¹„ë””ì˜¤ ì •ë³´ (í”„ë ˆì„ í¬ê¸°, FPS)
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0:
            fps = 30

        # ë¹„ë””ì˜¤ ì €ì¥ ê°ì²´ ì´ˆê¸°í™”
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

        # í”„ë ˆì„ ì²˜ë¦¬
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model(frame)

            # íƒì§€ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            detection_text = ""

            # ê° íƒì§€ ê²°ê³¼ ì²˜ë¦¬
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì„¸ê¸°
                    class_counts = {}
                    for box in boxes:
                        class_id = int(box.cls[0])
                        class_name = model.names[class_id]
                        confidence = float(box.conf[0])

                        # ì‹ ë¢°ë„ê°€ ì¼ì • ì´ìƒì¸ ê²ƒë§Œ
                        if confidence > 0.5:  # ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥
                            if class_name in class_counts:
                                class_counts[class_name] += 1
                            else:
                                class_counts[class_name] = 1

                    # ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    if class_counts:
                        detection_parts = []
                        for class_name, count in class_counts.items():
                            detection_parts.append(f"{count} {class_name}")
                        detection_text = f"0: {frame.shape[1]}x{frame.shape[0]} " + ", ".join(detection_parts)

            # ê²°ê³¼ ì¶œë ¥
            if detection_text:
                print(detection_text)

            if detection_text.find("cat") > 0:
                print("ê´­ì´ë‹·!!!!! ì´ì¦ˆ ë””ìŠ¤ ê´­ì´?")

            result_frame = results[0].plot()
            stframe.image(result_frame, channels="BGR")

            out.write(result_frame)

        cap.release()
        out.release()

        st.success(f"YOLO ê²°ê³¼ ë¹„ë””ì˜¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
