import torch

torch.classes.__path__ = []

import streamlit as st
import cv2
import os
import tempfile
from ultralytics import YOLO
import time
from collections import deque

model = YOLO("./yolov8n.pt")
st.title("YOLOv8 ì‹¤ì‹œê°„ ê´­ì´ íƒì§€ with ê±°ë¦¬ ì¶”ì ")

# ê³ ì–‘ì´ ê±°ë¦¬ ì¶”ì ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
if 'cat_distance_history' not in st.session_state:
    st.session_state.cat_distance_history = deque(maxlen=30)  # ìµœê·¼ 30í”„ë ˆì„ ì €ì¥
if 'last_cat_detection_time' not in st.session_state:
    st.session_state.last_cat_detection_time = 0



# ê±°ë¦¬ì¸¡ì • í•¨ìˆ˜ 
def calculate_cat_distance(box, frame_width, frame_height):
    """ê³ ì–‘ì´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±°ë¦¬ ì¶”ì •"""
    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
    box_width = x2 - x1
    box_height = y2 - y1
    box_area = box_width * box_height
    frame_area = frame_width * frame_height
    relative_size = box_area / frame_area
    
    # ìƒëŒ€ì  í¬ê¸°ë¥¼ ê±°ë¦¬ ì ìˆ˜ë¡œ ë³€í™˜ (í´ìˆ˜ë¡ ê°€ê¹Œì›€)
    distance_score = relative_size * 1000
    return distance_score, box_area

# ì›€ì§ì„ ë¶„ì„ í•¨ìˆ˜ 
def analyze_cat_movement(distance_history):
    """ê³ ì–‘ì´ì˜ ì›€ì§ì„ ë¶„ì„"""
    if len(distance_history) < 5:
        return "ë¶„ì„ ì¤‘...", "neutral"
    
    recent_distances = list(distance_history)[-5:]  # ìµœê·¼ 5ê°œ
    if len(recent_distances) >= 2:
        # ê±°ë¦¬ ë³€í™” ê³„ì‚°
        distance_change = recent_distances[-1] - recent_distances[0]
        change_percent = (distance_change / recent_distances[0]) * 100 if recent_distances[0] > 0 else 0
        
        if change_percent > 10:  # 10% ì´ìƒ ì¦ê°€
            return f"ê³ ì–‘ì´ê°€ ë‹¤ê°€ì˜¤ê³  ìˆìŠµë‹ˆë‹¤! (+{change_percent:.1f}%)", "approaching"
        elif change_percent < -10:  # 10% ì´ìƒ ê°ì†Œ
            return f"ê³ ì–‘ì´ê°€ ë©€ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤! ({change_percent:.1f}%)", "moving_away"
        else:
            return f"ê³ ì–‘ì´ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤. (ë³€í™”: {change_percent:.1f}%)", "stable"
    
    return "ë¶„ì„ ì¤‘...", "neutral"


#####
    # ì›¹ìº  ì„¤ì •
camera_index = st.selectbox("ì¹´ë©”ë¼ ì„ íƒ", [0, 1])

# ê±°ë¦¬ ì¶”ì  ì„¤ì •
st.sidebar.header("ê³ ì–‘ì´ ê±°ë¦¬ ì¶”ì  ì„¤ì •")
track_distance = st.sidebar.checkbox("ê±°ë¦¬ ì¶”ì  í™œì„±í™”", value=True)
confidence_threshold = st.sidebar.slider("ì‹ ë¢°ë„ ì„ê³„ê°’", 0.1, 1.0, 0.5, 0.1)

# ì›¹ìº  ì‹œì‘ ë²„íŠ¼
if st.button("ì›¹ìº  ì‹œì‘"):
    cap = cv2.VideoCapture(camera_index)
    
    if not cap.isOpened():
        st.error("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
    else:
        stframe = st.empty()
        distance_info = st.empty()
        movement_info = st.empty()
        stop_button = st.button("ì›¹ìº  ì¤‘ì§€")
        
        # ì›¹ìº  ì •ë³´
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0:
            fps = 30
        
        st.info(f"ì¹´ë©”ë¼ í•´ìƒë„: {frame_width}x{frame_height}, FPS: {fps}")
        
        # ì‹¤ì‹œê°„ ì²˜ë¦¬
        while cap.isOpened() and not stop_button:
            ret, frame = cap.read()
            if not ret:
                st.error("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            results = model(frame)
            
            # íƒì§€ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            detection_text = ""
            cat_detected = False
            current_cat_distance = None
            
            # ê° íƒì§€ ê²°ê³¼ ì²˜ë¦¬
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì„¸ê¸°
                    class_counts = {}
                    for box in boxes:
                        class_id = int(box.cls[0])
                        class_name = model.names[class_id]
                        confidence = float(box.conf[0])
                        
                        # ì‹ ë¢°ë„ê°€ ì¼ì • ì´ìƒì¸ ê²ƒë§Œ
                        if confidence > confidence_threshold:
                            if class_name in class_counts:
                                class_counts[class_name] += 1
                            else:
                                class_counts[class_name] = 1
                            
                            # ê³ ì–‘ì´ ê±°ë¦¬ ì¶”ì 
                            if track_distance and class_name == "cat":
                                cat_detected = True
                                distance_score, box_area = calculate_cat_distance(box, frame_width, frame_height)
                                current_cat_distance = distance_score
                                
                                # ê±°ë¦¬ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                                st.session_state.cat_distance_history.append(distance_score)
                                st.session_state.last_cat_detection_time = time.time()
                    
                    # ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    if class_counts:
                        detection_parts = []
                        for class_name, count in class_counts.items():
                            detection_parts.append(f"{count} {class_name}")
                        detection_text = f"0: {frame.shape[1]}x{frame.shape[0]} " + ", ".join(detection_parts)
            
            # ê²°ê³¼ ì¶œë ¥
            if detection_text:
                st.write(f"íƒì§€ ê²°ê³¼: {detection_text}")
            
            # ê³ ì–‘ì´ ê±°ë¦¬ ì •ë³´ í‘œì‹œ
            if cat_detected and current_cat_distance is not None:
                distance_info.success(f"ê³ ì–‘ì´ ë°œê²¬! ê±°ë¦¬ ì ìˆ˜: {current_cat_distance:.2f}")
                
                # ì›€ì§ì„ ë¶„ì„
                movement_text, movement_status = analyze_cat_movement(st.session_state.cat_distance_history)
                
                if movement_status == "approaching":
                    movement_info.warning(f"{movement_text}")
                elif movement_status == "moving_away":
                    movement_info.info(f"ğŸ“ {movement_text}")
                else:
                    movement_info.success(f"{movement_text}")
                    
            elif track_distance:
                # ê³ ì–‘ì´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ì§€ë§Œ ìµœê·¼ì— ê°ì§€ëœ ê²½ìš°
                time_since_last = time.time() - st.session_state.last_cat_detection_time
                if time_since_last < 5:  # 5ì´ˆ ì´ë‚´ì— ê°ì§€ëœ ê²½ìš°
                    distance_info.info("ê³ ì–‘ì´ë¥¼ ì°¾ëŠ” ì¤‘...")
                    movement_info.empty()
                else:
                    distance_info.empty()
                    movement_info.empty()
            
            if detection_text.find("cat") > 0:
                st.success("ê³ ì–‘ì´ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
            
            result_frame = results[0].plot()
            stframe.image(result_frame, channels="BGR")
            
            # ëŒ€ê¸° 
            time.sleep(0.1)
        
        cap.release()
        st.success("ì›¹ìº ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
